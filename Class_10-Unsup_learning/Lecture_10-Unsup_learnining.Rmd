---
title: 'Class10: Machine Learning Project'
author: "Michael Overton"
output: github_document
always_allow_html: TRUE
---

Using PCA and heirarchical clustering to investigate data from the Wisconsin Breast Cancer Diagnostic Data Set, first reported by K. P. Benne and O. L. Mangasarian: "Robust Linear Programming Discrimination of Two Linearly Inseparable Sets".
```{r}
fna.data <- "Class_10_data/WisconsinCancer.csv"
wisc.df <- read.csv(fna.data)

```

Q1. What type of object is returned from the read.csv() function?

```{r}
class(wisc.df)
```

Q2. How many observations (i.e. patients) are in this dataset? 

```{r}
length(unique(wisc.df$id))
```

Q3. How many of the observations have a malignant diagnosis? 

```{r}
sum(wisc.df$diagnosis == "M")
```

Q4. How many variables/features in the data are suffixed with _mean? 

```{r}
wisc.data <- as.matrix(wisc.df[ ,3:32])
rownames(wisc.data) <- wisc.df$id

length(grep("_mean", colnames(wisc.data)))

```


Q5. Why do you think we are using the indices 3:32 here?

> The specific sample IDs are converted into the rownames, and we want this to be unsupervised, so we do not want to bias our analysis with the final diagnoses, we want to be able to predict malignancy from the data
  
```{r}
diagnosis <- as.vector(wisc.df$diagnosis)
wisc.pr <- prcomp(wisc.data, scale. = T)

summary(wisc.pr)

```


```{r}
biplot(wisc.pr)

```

Q10. What stands out to you about this plot? Is it easy or difficult to understand? Why?

> The plot is extremely cluttered, as ID names are used as points rather than some marker. As well, the various factors influencing the data point locations are numerous and the names are cluttered.

```{r}
plot(wisc.pr$x, col = (diagnosis=="M")+1, 
     xlab = "PC1", ylab = "PC2")

```

Q11. Generate a PC1 vs PC2 plot as described above colored by diagnosis. What do the points in this plot represent? What are the red points? Where did this coloring come from and why were these colors chosen by R?

> Each point is a particular biopsy result, the red points are malignant diagnoses. By using the conversion of logical to numeric, R looks up the associated colors in a palette to the values 1 and 0 (or actually, 2 and 1, because we add 1 to the logical) which are 1=black and 2=red.
  

```{r}
plot(wisc.pr$x[,c(1,3)], col = (diagnosis=="M")+1, 
     xlab = "PC1", ylab = "PC3")

```

Q12. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

> PC3 is less informative than PC2. There is less partitioning of the datapoints in PC3

Variance explained
In this section, scree plots show the proportion of variance explained as the number of principal components increases. The data from PCA must be prepared for these plots, as there is not a built-in function in base R to create them directly from the PCA model.
  
```{r}
pr.var <- wisc.pr$sdev^2
pve <- pr.var / sum(pr.var)

barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )

```
  
  
  
```{r}
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)

```

Q13. For the first principal component, and using two significant figures, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature radius_mean? 

Q14. For the first principal component, and using two significant figures, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature smoothness_se? 

Q15. Which original variable contributes most to PC1?

```{r}
round(wisc.pr$rotation[,1][["radius_mean"]], 2)
round(wisc.pr$rotation[,1][["smoothness_se"]], 3)
max(abs(wisc.pr$rotation[,1]))

```


Hierarchical clustering of case data
The goal of this section is to do hierarchical clustering of the observations. This type of clustering does not assume in advance the number of natural groups that exist in the data.

As part of the preparation for hierarchical clustering, the distance between all pairs of observations are computed. There are different ways to link clusters together, with single, complete, and average being the most common methods.

Q16. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
# Scale the wisc.data data: data.scaled
library(scales)

data.scaled <- rescale(wisc.data)

data.dist <- dist(data.scaled, method="euclidean")
wisc.hclust <- hclust(data.dist, method="ward.D")

plot(wisc.hclust)
abline(a=4.5, b=0, col="red", lty=2)
```


Selecting number of clusters
This section compares the outputs from the hierarchical clustering model to the actual diagnoses. Normally when performing unsupervised learning like this, a target variable (i.e. known answer or labels) isn't available. We do have it with this dataset, however, so it can be used to check the performance of the clustering model.

```{r}

wisc.k.tbls <- vector("list", 9)
for (i in 2:10) {
  wisc.hclust.k <- cutree(wisc.hclust, k=i)
  wisc.k.tbl <- table(wisc.hclust.k, diagnosis)
  wisc.k.tbls[[i-1]] <- wisc.k.tbl
}

```
The clustering does not fully resolve into Benign and Malignant groups. In particular k=5 results into four well-partitioned goups, but one group that is a mixture.

Q17. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10? How would you determine what better is in this context?
> The k=5 seems to be the point of inflection, where the production of new clusters that segregate along diagnosis essentially ceases.

Clustering with PCA
This final section puts together several steps used earlier. The PCA model required significantly fewer features to describe 70%, 80% and 95% of the variability of the data. In addition to normalizing data and potentially avoiding over-fitting, PCA also uncorrelates the variables, sometimes improving the performance of other modeling techniques.

```{r}
wisc.hc.pr <- hclust(dist(wisc.pr$x[,1:2]), method="ward.D2")

grps <- cutree(wisc.hc.pr, k=2)

table(grps, diagnosis)

plot(wisc.pr$x[ ,1:2], col=grps, pch=20+(diagnosis=="M"))
plot(wisc.pr$x[,1:2], col=2-(diagnosis=="M"), pch=20+(diagnosis=="M"))
```

Q18. How well does k-means separate the two diagnoses? How does it compare to your hclust results?

```{r}
wisc.km <- kmeans(scale(wisc.data), centers= 2, nstart= 20)
table(wisc.km$cluster, diagnosis)
```

> The two methods yield very similar results

```{r}
library(rgl)
plot3d(wisc.pr$x[,1:3], xlab="PC 1", ylab="PC 2", zlab="PC 3", cex=1.5, size=1, type="s", col=grps)
rglwidget(width = 400, height = 400)
```


Q19. How well does the newly created model with four clusters separate out the two diagnoses?

```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(data.dist, method="ward.D2")

wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=4)
table(wisc.pr.hclust.clusters, diagnosis)
```

Q20. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
table(wisc.km$cluster, diagnosis)
wisc.k.tbls[[3]]
table(wisc.pr.hclust.clusters, diagnosis)
```

> In this case, the PCA method seems to have performed worse than the heirarchical clustering. While cluster 3 in the PCA method does detect more true negatives, cluster 3 is even more well mixed in the PCA than in the heirarchical model. However, K-means performs the best.

Q21. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?
PCA is more sensitive, heirarchical is mmore specific.

```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc

```


Q22. Which of these new patients should we prioritize for follow up based on your results? 

```{r}
plot(wisc.pr$x[,1:2], col=3-grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Patients with a malignant diagnosis are colored red, therefore Patient 2 should follow up.

